# LC 697 â€“ Degree of an Array  
## Comparison of Three Implementations

---

# 1ï¸âƒ£ OneHashMap Approach

## ğŸ” Strategy
- Count frequency using one `HashMap`
- Find max frequency (degree)
- Collect elements having max frequency
- For each such element:
  - Rescan array to find first occurrence
  - Rescan array to find last occurrence
  - Compute subarray length

## â± Time Complexity
- Counting â†’ O(n)
- Collecting max elements â†’ O(n)
- Rescanning array for each max element â†’ O(nÂ² worst case)

**Overall: O(nÂ²) worst case**

Why?
Because for each high-frequency element, the array is scanned again.

## ğŸ’¾ Space Complexity
- O(n) for frequency map
- O(k) for list of max elements

## âŒ Drawbacks
- Repeated rescanning
- Inefficient for large inputs
- Avoidable extra work

## ğŸ§  Learning Point
Rescanning is a red flag.  
If you are searching for first/last repeatedly, store that info during first pass.

---

# 2ï¸âƒ£ ThreeHashMap Approach

## ğŸ” Strategy
- Store:
  - `count`
  - `first index`
  - `last index`
- Compute degree during traversal
- Final loop iterates over entire array again to compute min length

## â± Time Complexity
- First traversal â†’ O(n)
- Second traversal over array â†’ O(n)

**Overall: O(n)**

## ğŸ’¾ Space Complexity
- Three HashMaps â†’ O(n)

## âš ï¸ Minor Inefficiencies
- First index logic unnecessarily uses `Math.min`
- Last index logic unnecessarily uses `Math.max`
- Final loop iterates over `nums` instead of `map.keySet()`, causing redundant checks

## ğŸ§  Learning Point
Metadata should be:
- Stored once
- Not recalculated
- Not rechecked multiple times

This version is optimal in complexity but not minimal in structure.

---

# 3ï¸âƒ£ Optimal Approach

## ğŸ” Strategy
- Store:
  - `count`
  - `first index`
  - `last index`
- First occurrence stored only once
- Last occurrence updated naturally during traversal
- Final loop iterates only over unique keys

## â± Time Complexity
- First pass â†’ O(n)
- Second pass over unique elements â†’ O(n worst case)

**Overall: O(n)**

No rescanning.
No redundant checks.

## ğŸ’¾ Space Complexity
- Three HashMaps â†’ O(n)

## âœ… Why Itâ€™s Best
- Clean logic
- No unnecessary comparisons
- No repeated scans
- Fully optimal
- Interview-ready structure

---

# ğŸ”¥ Direct Comparison

| Version        | Time Complexity | Space | Efficiency Level |
|---------------|-----------------|-------|------------------|
| OneHashMap   | O(nÂ²)           | O(n)  | âŒ Inefficient    |
| ThreeHashMap | O(n)            | O(n)  | âœ… Good           |
| Optimal      | O(n)            | O(n)  | ğŸš€ Best Structure |

---

# ğŸ¯ Core Optimization Pattern Learned

Instead of:
> â€œFind it later by searching againâ€

Do:
> â€œStore it when you see itâ€

This pattern:
- Eliminates nested scanning
- Converts O(nÂ²) â†’ O(n)
- Is frequently tested in interviews

---

# ğŸš€ Final Recommendation

Use the **Optimal Approach**.

It is:
- Time optimal
- Clean
- Minimal
- Scalable
- Interview safe

---

# ğŸ§  Concept Upgrade Achieved

You moved from:
- Brute force thinking

To:
- Metadata-driven optimization

That is a major improvement in algorithmic maturity.
